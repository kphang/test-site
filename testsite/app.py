import uvicorn

from fastapi import FastAPI, Request, Response
from pydantic import BaseSettings

from slowapi import Limiter, _rate_limit_exceeded_handler
from slowapi.util import get_remote_address
from slowapi.errors import RateLimitExceeded

import logging
import sys
from datetime import datetime
from enum import StrEnum, auto
import random
from anyio import Semaphore, sleep


testsite = FastAPI(title="Test Site")
logging.basicConfig(
    level=logging.INFO, format="[%(levelname)s]: %(asctime)s - %(message)s"
)


class Period(StrEnum):
    second = auto()
    minute = auto()
    hour = auto()
    day = auto()
    month = auto()
    year = auto()


class LimitSettings(BaseSettings):
    rate: int = 10
    rateperiod: Period = "second"
    quota: int = 10000
    quotaperiod: Period = "day"
    maxconcur: int = 10
    throttle: bool = False
    maxranddelay: int | None = None
    
    class Config:
        env_file = "testsite/limitsettings.txt"


# TODO: validation of limit combinations (rate and period need to be both present, maxconcur > 0
# TODO: validation of maxranddelay > 0
# TODO: validation of throttle requires at least one of the rate/quota and periods

###

limitsettings = LimitSettings()
limiter = Limiter(
    key_func=get_remote_address, headers_enabled=True, strategy="moving-window"
)

testsite.state.limiter = limiter
testsite.add_exception_handler(RateLimitExceeded, _rate_limit_exceeded_handler)
idlist = ["127.0.0.1", "/limited"]
semaphore = Semaphore(limitsettings.maxconcur)


### FUNCTIONS


async def default_response(request: Request) -> dict:
    """Creates a standard diagnostic response that includes information about the endpoint hit and the data sent.
    Also includes timestamps indicating the point at which the request was received and filled. This can be used
    to compare against the actual request and response time on the client side.

    Args:
        request (Request): Request object generated by hitting endpoint        

    Returns:
        dict: Standard diagnostic response
    """
    # because body is an awaitable cannot be a pydantic model without more complex solutions
    response = {
        "request": {
            "path": request["path"],
            "headers": request.headers,
            "queryParams": request.query_params,
            "clientAddress": request.client,
            "requestBody": await request.body(),
        },
        "limitSettings": {},
        "receivedAt": request.state.receivedAt,
        "fulfilledAt": datetime.now(),
    }
    if request["path"] == "/limited":
        response["limitSettings"] = limitsettings.dict()
        

    return response


async def throttle_excess() -> bool:
    
    cur_limit = sys._getframe(1).f_locals["self"].limit                
    l_results = {}
    
    for l in limiter._route_limits["app.limited_endpoint"]:        
        if limitsettings.throttle and not limiter.limiter.test(l.limit,*idlist):
            l_results[l.limit]= True
        else:
            l_results[l.limit]= False    

    if any(l_results.values()):        
        for k,v in l_results.items():
            if k==cur_limit and not v:
                limiter.limiter.hit(k,*idlist)
        return True        
    else:
        return False
        
        
### ENDPOINTS

@testsite.middleware("http")
async def middleware(request: Request, call_next):
    
    request.state.receivedAt = datetime.now()
        
    if limitsettings.throttle:
        request.state.throttled = False
        
    for l in limiter._route_limits["app.limited_endpoint"]:
        logging.info(f"{(l.limit, *idlist)} available: {limiter.limiter.get_window_stats(l.limit, *idlist)[1]}")
        if limitsettings.throttle and not limiter.limiter.test(l.limit,*idlist):
            request.state.throttled = True                
                                
    response = await call_next(request)    
        
    if limitsettings.throttle and request.state.throttled:
        logging.info("Request throttled")        
        await sleep((datetime.now()-request.state.receivedAt).total_seconds())        
        
    return response

@testsite.get("/")
@testsite.post("/")
async def index(request: Request):
    """Standard endpoint for non-limited testing.

    Returns:
        dict: Standard diagnostic response
    """    
    response = await default_response(request)
    
    return response


@testsite.get("/limited")
@testsite.post("/limited")
@limiter.limit(
    f"{limitsettings.rate}/{limitsettings.rateperiod},{limitsettings.quota}/{limitsettings.quotaperiod}",exempt_when=throttle_excess
)  # TODO: needs to handle Nones
async def limited_endpoint(request: Request, response: Response) -> Response:
    """Endpoint to test BADGER's ability to handle different API limits.

    Args:
        request (Request): _description_
        response (Response): _description_

    Returns:
        dict: Standard diagnostic response
    """    
    
    """
    Supports following limits:
        - # of requests per defined period
        - max # of concurrent requests
        - minimum required delay in seconds between subsequent requests
        - add a randomized delay up to a maximum of seconds before providing a response
    """

    async with semaphore:
        logging.info(f"{semaphore._value} semaphore available")

        if limitsettings.maxranddelay is not None and limitsettings.maxranddelay > 0:
            random.seed()
            request.state.randdelay = random.uniform(0, limitsettings.maxranddelay)
            logging.info(f"{request.state.randdelay}s of random delay")
            await sleep(request.state.randdelay)
        else:
            request.state.randdelay = 0

        response = await default_response(request)

    logging.info(f"{semaphore._value} semaphore available")

    return response



if __name__ == "__main__":
    uvicorn.run("app:testsite", port=9000, reload=True)
