import uvicorn

from fastapi import FastAPI, Request, Response
from pydantic import BaseSettings, validator, root_validator, dataclasses
from typing import Literal

from slowapi import Limiter, _rate_limit_exceeded_handler
from slowapi.util import get_remote_address
from slowapi.errors import RateLimitExceeded
from anyio import Semaphore, sleep

import logging
import sys
from datetime import datetime
import random



testsite = FastAPI(title="Test Site")
logging.basicConfig(
    level=logging.INFO, format="[%(levelname)s]: %(asctime)s - %(message)s"
)

### Classes

@dataclasses.dataclass
class RateQuota():
    """Used for rates and quotas to require the combination of an amount and period. 
    Provides the method to create the limiter string.
    """
    amount: int
    period: Literal["second","minute","hour","day","month","year"]
    
    def limitstr(self) -> str:
        return f"{self.amount}/{self.period}"

class LimitSettings(BaseSettings):
    """Stores limitation settings based on loaded file and performs validation for at least one rate/quota.
    """
    rate: RateQuota | None = None
    quota: RateQuota | None = None
    maxconcur: int = 10
    throttle: bool = False
    maxranddelay: int = 0
    
    class Config:
        env_file = "testsite/limitsettings.txt"
    
    @validator("maxconcur")
    def checkmaxconcur(cls,v):
        if v < 1:
            raise ValueError("If specified, maxconcur must be greater than 0")
        
        return v
    
    @root_validator
    def checkratequotas(cls,values):        
        if not any([values["rate"], values["quota"]]):
            raise ValueError("Either a rate or quota must be provided")    
        else:
            return values    
    
    def fulllimitstr(self) -> str:
        """Returns:
            str: Concatenated limiter string for decorator
        """                
        return ",".join([rq.limitstr() for rq in filter(None,[self.rate, self.quota])])
    
    
### Initialize limits

limitsettings = LimitSettings()
limiter = Limiter(
    key_func=get_remote_address, headers_enabled=True, strategy="moving-window"
)

testsite.state.limiter = limiter
testsite.add_exception_handler(RateLimitExceeded, _rate_limit_exceeded_handler)
idlist = ["127.0.0.1", "/limited"] # standard since testsite is for internal testing and only the /limited endpoint is limited
semaphore = Semaphore(limitsettings.maxconcur)


### Functions

async def default_response(request: Request) -> dict:
    """Creates a standard diagnostic response that includes information about the endpoint hit and the data sent.
    Also includes timestamps indicating the point at which the request was received and filled. This can be used
    to compare against the actual request and response time on the client side.

    Args:
        request (Request): Request object generated by hitting endpoint        

    Returns:
        dict: Standard diagnostic response
    """
    # because body is an awaitable cannot be a pydantic model without more complex solutions
    response = {
        "request": {
            "path": request["path"],
            "headers": request.headers,
            "queryParams": request.query_params,
            "clientAddress": request.client,
            "requestBody": await request.body(),
        },
        "limitSettings": {},
        "receivedAt": request.state.receivedAt,
        "fulfilledAt": datetime.now(),
    }
    if request["path"] == "/limited":
        response["limitSettings"] = limitsettings.dict()
        

    return response


async def throttle_excess() -> bool:
    """Called by limiters to check for the need to throttle requests if throttling is enabled.
    This is called separately by each limiter. This handles two issues: 
    (1) prevent the last limiter's call from overriding other throttles,
    (2) continue to log hits to limiters that don't need to be throttled by manually triggering a hit.    

    Returns:
        bool: Whether the user's requests to the endpoint should be throttled
    """                    
    
    l_results = {}
    for l in limiter._route_limits["app.limited_endpoint"]: # test each endpoint whether it has capacity and make a note       
        if limitsettings.throttle and not limiter.limiter.test(l.limit,*idlist):
            l_results[l.limit]= True
        else:
            l_results[l.limit]= False    

    if any(l_results.values()): # if any limiter needs to be throttled, manually increment those that do not       
        cur_limit = sys._getframe(1).f_locals["self"].limit
        for k,v in l_results.items():
            if k==cur_limit and not v: # only increment a limit on its throttle check (not multiple times)
                limiter.limiter.hit(k,*idlist)
        return True        
    else:
        return False
        
        
### ENDPOINTS

@testsite.middleware("http")
async def middleware(request: Request, call_next) -> Response:
    """Middleware:
    (1) tracks request receive time to provide in response as well as applicaiton of throttling
    (2) provides logging on availability within rate limits and throttle status
    (3) applies throttling consequence of doubling processing time (only noticeable when processing time is meaningful
    such as when adding a random delay.
    """
    
    request.state.receivedAt = datetime.now()
        
    if request.url.path=="/limited": # this portion of the middleware only applies the limited endpoint
        if limitsettings.throttle:
            request.state.throttled = False
            
        for l in limiter._route_limits["app.limited_endpoint"]:
            logging.info(f"{(l.limit, *idlist)} available before request: {limiter.limiter.get_window_stats(l.limit, *idlist)[1]}")
            if limitsettings.throttle and not limiter.limiter.test(l.limit,*idlist):
                request.state.throttled = True                
                                
    response = await call_next(request)    
        
    if limitsettings.throttle and request.state.throttled:
        logging.info("Request throttled")        
        await sleep((datetime.now()-request.state.receivedAt).total_seconds())        
        
    return response

@testsite.get("/")
@testsite.post("/")
async def index(request: Request):
    """Standard endpoint for non-limited testing.

    Returns:
        dict: Standard diagnostic response
    """    
    response = await default_response(request)
    
    return response


@testsite.get("/limited")
@testsite.post("/limited")
@limiter.limit(f"{limitsettings.fulllimitstr()}",exempt_when=throttle_excess)
async def limited_endpoint(request: Request, response: Response) -> Response:
    """Endpoint to test BADGER's ability to handle different API limits.

    Returns:
        dict: Standard diagnostic response
    """    

    async with semaphore:
        logging.info(f"{semaphore._value} semaphore available")

        # apply random delay if enabled before responding
        if limitsettings.maxranddelay > 0:
            random.seed()
            request.state.randdelay = random.uniform(0, limitsettings.maxranddelay)
            logging.info(f"{request.state.randdelay}s of random delay")
            await sleep(request.state.randdelay)
        else:
            request.state.randdelay = 0

        response = await default_response(request)

    logging.info(f"{semaphore._value} semaphore available")

    return response



if __name__ == "__main__":
    uvicorn.run("app:testsite", port=9000, reload=True)
