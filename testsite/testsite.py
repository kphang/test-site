import uvicorn

from fastapi import FastAPI, Request, Depends
from pydantic import BaseModel

from slowapi import Limiter, _rate_limit_exceeded_handler
from slowapi.util import get_remote_address
from slowapi.errors import RateLimitExceeded

from datetime import datetime
from typing import Optional
from enum import StrEnum, auto
import logging
import random
from anyio import Semaphore, create_task_group, sleep

testsite = FastAPI(title="Test Site")

limiter = Limiter(key_func=get_remote_address)
testsite.state.limiter = limiter
testsite.add_exception_handler(RateLimitExceeded, _rate_limit_exceeded_handler)


class Period(StrEnum):
    second = auto()
    minute = auto()
    hour = auto()
    day = auto()
    month = auto()
    year = auto()
    
class LimitParams(BaseModel):    
    rate: Optional[int] = 10 
    rateperiod: Optional[Period] = "second"
    quota: Optional[int] = 10000
    quotaperiod: Optional[Period] = "day"
    maxconcur: Optional[int] = 10
    throttleatpct: Optional[float] = None
    maxranddelay: Optional[float] = 0.0
              
# TODO: validation of limit combinations (rate and period need to be both present, maxconcur > 0        



async def default_response(request: Request, semaphore: Semaphore, limitparams: Optional[LimitParams] = None, ) -> dict :
    """Creates a standard diagnostic response that includes information about the endpoint hit and the data sent.
    Also includes timestamps indicating the point at which the request was received and filled. This can be used
    to compare against the actual request and response time on the client side.

    Args:
        request (Request): Request object generated by hitting endpoint
        limitparams (LimitParams, optional): Pydantic model used to store query parameters for limit configurations.
            Defaults to None.

    Returns:
        dict: Standard diagnostic response
    """
    # because body is an awaitable cannot be a pydantic model without more complex solutions    
    response = {        
        "request": {
            "path": request["path"],
            "headers": request.headers,
            "queryParams": request.query_params,
            "clientAddress": request.client,
            "requestBody": await request.body(),       
        },
        "config": {
            "LimitParams": {} if limitparams is None else limitparams.dict(),
            "randdelay": None if limitparams is None else request.state.randdelay
        },        
        "receivedAt": request.state.receivedAt,
        "fulfilledAt": datetime.now()
    }            
    return response

        
    
@testsite.get("/")
@testsite.post("/")
async def index(request: Request):    
    """Standard endpoint for non-limited testing.

    Returns:
        dict: Standard diagnostic response
    """
    request.state.receivedAt = datetime.now()
    response = await default_response(request)    
    return response


@testsite.get("/limited")
@testsite.post("/limited")
@limiter.limit("{limitparams.rate}/{limitparams.rateperiod},{limitparams.quota}/{limitparams.quotaperiod}")
async def limited_endpoint(request: Request, limitparams: LimitParams = Depends()):    
    """Endpoint to test BADGER's ability to handle different API limits.
    
    Supports following limits:
        - # of requests per defined period
        - max # of concurrent requests
        - minimum required delay in seconds between subsequent requests
        - add a randomized delay up to a maximum of seconds before providing a response

    Args:
        request (Request): _description_
        limitparams (_type_, optional): _description_. Defaults to LimitParams().

    Returns:
        dict: Standard diagnostic response
    """    
    """Endpoint to test BADGER's ability to handle different API limits.
    
    Supports following limits:
        - # of requests per defined period
        - max # of concurrent requests
        - minimum required delay in seconds between subsequent requests
        - add a randomized delay up to a maximum of seconds before providing a response
    
    Args:
        rate (int, optional): _description_. Defaults to 10.
        period (str, optional): _description_. Defaults to "seconds".
        maxconcur (int, optional): _description_. Defaults to 10.
        delaysub (float, optional): _description_. Defaults to 0.0.
        maxrandomdelay (float, optional): _description_. Defaults to 0.0.

    Returns:
        dict: Standard diagnostic response
    """
    semaphore = Semaphore(limitparams.maxconcur) # TODO: I don't think this works - I think every individual get spawns semaphores
    # TODO: I think I need to have something set the config for the endpoint and then hit the endpoint separate from the configuration
    # Option 1: arguments on startup
    # Option 2: separate configuration endpoint
    async with semaphore:

        request.state.receivedAt = datetime.now()                
        
        if limitparams.maxranddelay is not None and limitparams.maxranddelay > 0:
            random.seed()        
            request.state.randdelay = random.uniform(0,limitparams.maxranddelay)
            await sleep(request.state.randdelay)
        else:
            request.state.randdelay = 0
        
        # TODO: maxconcur, throttle
        
        response = await default_response(request, limitparams)    
    
    return response


if __name__ == "__main__":
    uvicorn.run("testsite:testsite", reload=True)